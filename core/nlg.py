"""NLG interface and a simple generator implementation.

Provide an interface so we can later plug in a remote LLM or templating
service while keeping tests and local runs simple.
"""
from typing import Dict, Any, Optional, Union
import os
from .ad_generator import generate_ad as _generate_ad
from .llm import safe_chat_completion
from .cache import get_cached, set_cached
import json
import hashlib


def _hash_analysis(a: Dict[str, Any]) -> str:
    try:
        r = json.dumps(a, sort_keys=True, ensure_ascii=False)
    except Exception:
        r = str(a)
    return hashlib.sha256(r.encode("utf-8")).hexdigest()


def _validate_ad_schema(ad_obj: Dict[str, Any]) -> bool:
    """Lightweight validation for the generated ad JSON.
        Expected keys:
            - `hooks` (str)
            - `segments` (list of {start, end, text, visual_cue})
            - `cta` (str)
            - `length_seconds` (int)
    """
    if not isinstance(ad_obj, dict):
        return False
    if "hooks" not in ad_obj or not isinstance(ad_obj["hooks"], str):
        return False
    if "segments" not in ad_obj or not isinstance(ad_obj["segments"], list):
        return False
    for seg in ad_obj["segments"]:
        if not isinstance(seg, dict):
            return False
        for k in ("start", "end", "text"):
            if k not in seg:
                return False
    if "cta" in ad_obj and not isinstance(ad_obj["cta"], str):
        return False
    return True


class NLGInterface:
    """A minimal natural-language generation interface."""

    def generate(self, analysis: Dict[str, object]) -> Union[str, Dict[str, Any]]:
        """Generate ad content from analysis.

        Implementations should return either a plain string (ad copy) or
        a structured dict representing an ad timeline. Subclasses should
        implement this method to provide specific backends.
        """
        raise NotImplementedError()


class SimpleNLG(NLGInterface):
    """Thin wrapper around the local `ad_generator.generate_ad`.

    Keeps the same function signature but provides a class-based backend
    for dependency injection.
    """

    def generate(self, analysis: Dict[str, object]) -> Union[str, Dict[str, Any]]:
        return _generate_ad(analysis)


class LLMNLG(NLGInterface):
    """LLM-backed NLG producing structured JSON ad specs.

    It uses `core.llm.safe_chat_completion` and a file-backed cache to
    avoid repeated costly calls. On failure it falls back to `SimpleNLG`.
    """

    def __init__(self, model: str = "gpt-4o-mini", cache_ttl: int = 60 * 60 * 24, mock: Optional[bool] = None):
        self.model = model
        self.cache_ttl = cache_ttl
        self.mock = mock
        # Try to load jsonschema and the schema file; fall back to lightweight validation
        try:
            import jsonschema
            self._jsonschema = jsonschema
            try:
                schema_path = os.path.join(os.path.dirname(__file__), "schemas", "ad_schema.json")
                with open(schema_path, "r", encoding="utf-8") as sf:
                    self._ad_schema = json.load(sf)
            except Exception:
                self._ad_schema = None
        except Exception:
            self._jsonschema = None
            self._ad_schema = None

    def _build_prompt(self, analysis: Dict[str, Any]) -> str:
        # Keep prompt concise and request strict JSON
        parts = [
            "You are an ad writer. Given the analysis supplied, produce a JSON object with the following keys:",
            "- hooks: a one-line hook (first 3s)",
            (
                "- segments: array of {start:float, end:float, text:str, visual_cue:str}"
                " representing the ad timeline"
            ),
            "- cta: short call-to-action string",
            "- length_seconds: integer approximate total length",
            "Return only valid JSON. Analysis:",
        ]
        return "\n".join(parts) + "\n" + json.dumps(analysis, ensure_ascii=False)

    def generate(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Generate a structured ad spec using the LLM backend.

        Behavior:
        - Use a cache key derived from analysis to avoid repeat LLM calls.
        - If the LLM returns valid JSON matching the schema (or the
          lightweight validator), cache and return it.
        - On validation failure, return a safe fallback generated by
          `ad_generator.generate_ad` wrapped in a minimal schema.
        """

        key = _hash_analysis(analysis) + ":ad_v1"
        cached = get_cached(key)
        if cached:
            return cached

        prompt = self._build_prompt(analysis)
        messages = [
            {"role": "system", "content": "You are a concise ad creative assistant."},
            {"role": "user", "content": prompt},
        ]

        # Ask the LLM for strict JSON output; `safe_chat_completion` will
        # attempt to parse JSON when `prefer_json=True` and otherwise
        # return the raw assistant content. We pass through `mock` so UI
        # controls can force deterministic test outputs.
        resp = safe_chat_completion(messages, model=self.model, prefer_json=True, mock=self.mock)
        # resp may be tuple when return_usage used; handle dict or string
        parsed = None
        if isinstance(resp, tuple):
            parsed = resp[0]
        else:
            parsed = resp

        validation_error = None
        is_valid = False
        if isinstance(parsed, dict):
            # Prefer jsonschema if available
            if self._jsonschema and self._ad_schema:
                try:
                    self._jsonschema.validate(instance=parsed, schema=self._ad_schema)
                    is_valid = True
                except Exception as e:
                    validation_error = str(e)
                    is_valid = False
            else:
                is_valid = _validate_ad_schema(parsed)

        if is_valid:
            set_cached(key, parsed, ttl_seconds=self.cache_ttl)
            return parsed

        # fallback: use simple generator and wrap in minimal schema
        ad_text = _generate_ad(analysis)
        fallback = {
            "hooks": (analysis.get("highlights") or [""])[0] if isinstance(analysis, dict) else "",
            "segments": [{"start": 0.0, "end": 15.0, "text": ad_text, "visual_cue": "text_on_screen"}],
            "cta": "Visit our site",
            "length_seconds": 15,
        }
        # Attach validation error to fallback so UI can surface it
        if validation_error:
            fallback["_validation_error"] = validation_error
        set_cached(key, fallback, ttl_seconds=self.cache_ttl)
        return fallback
